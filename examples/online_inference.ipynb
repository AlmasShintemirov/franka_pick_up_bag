{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rclpy, asyncio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from subscriber import Subscriber, get_observation, wait_for_message\n",
    "from sensor_msgs.msg import Image\n",
    "from std_msgs.msg import String, Float32MultiArray\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/irobotics/anaconda3/envs/octo/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
    "\n",
    "import cv2\n",
    "import jax\n",
    "import tensorflow_datasets as tfds\n",
    "import tqdm\n",
    "import mediapy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_CHECKPOINTS = \"/media/irobotics/Transcend/finetuned_checkpoints/v4_checkpoints/\"\n",
    "PATH_DATASET_ROSBAG = \"/media/irobotics/Transcend/isaacsim_data/v4_test/\"\n",
    "PATH_DATASET_TFDS = '/media/irobotics/Transcend/tensorflow_datasets/v4_test/example_dataset/1.0.0/'\n",
    "PATH_INFERENCE_RESULTS = \"/media/irobotics/Transcend/inference_result/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-25 14:43:20.017393: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-25 14:43:20.017434: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-25 14:43:20.018018: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-25 14:43:20.539919: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "WARNING:jax._src.xla_bridge:CUDA backend failed to initialize: Found cuDNN version 0, but JAX was built against version 8600, which is newer. The copy of cuDNN that is installed must be at least as new as the version against which JAX was built. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n",
      "WARNING:root:Using old attention computation from released December models.\n",
      "/home/irobotics/anaconda3/envs/octo/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from octo.model.octo_model import OctoModel\n",
    "\n",
    "model = OctoModel.load_pretrained(PATH_CHECKPOINTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-25 14:43:56.455551: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "# create RLDS dataset builder\n",
    "builder = tfds.builder_from_directory(builder_dir=PATH_DATASET_TFDS)\n",
    "ds = builder.as_dataset(split='train[:2]')\n",
    "iterator = iter(ds)\n",
    "episode = next(iterator)\n",
    "# sample episode + resize to 256x256 (default third-person cam resolution)\n",
    "steps = list(episode['steps'])\n",
    "images = [cv2.resize(np.array(step['observation']['image']), (256, 256)) for step in steps]\n",
    "# extract goal image & language instruction\n",
    "goal_image = images[-1]\n",
    "language_instruction = steps[100]['language_instruction'].numpy().decode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference begins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:'tasks' contains extra items compared to example_batch: {'image_primary', 'pad_mask_dict/image_primary'}\n"
     ]
    }
   ],
   "source": [
    "# create `task` dict\n",
    "# task = model.create_tasks(goals={\"image_primary\": goal_image[None]})   # for goal-conditioned\n",
    "task = model.create_tasks(goals={\"image_primary\": goal_image})\n",
    "task = model.create_tasks(texts=[language_instruction])                  # for language conditioned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rclpy.init(args=None)\n",
    "node = Subscriber()\n",
    "publisher = node.create_publisher(Float32MultiArray, 'online_eff_topic', 10)\n",
    "pub_msg = Float32MultiArray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect predicted and true actions\n",
    "pred_actions= []\n",
    "# true_actions = steps[:]['action']\n",
    "window = 2\n",
    "input_images_stack = [np.zeros((256, 256, 3)) for _ in range(window-1)]\n",
    "input_images_wrist_stack = [np.zeros((512, 512, 3)) for _ in range(window-1)]\n",
    "\n",
    "input_images = get_observation(node, Image, '/Camera_rgb', (256, 256, 3))\n",
    "input_images_wrist = get_observation(node, Image, '/Camera_wrist_rgb', (512, 512, 3))\n",
    "input_images_stack.append(input_images)\n",
    "input_images_wrist_stack.append(input_images_wrist)\n",
    "\n",
    "# cur_eff = np.array([0.26, 0.0, 0.4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def publish_efforts(pub_msg, trigger):\n",
    "    input_images, input_images_wrist = None, None\n",
    "    if not trigger:\n",
    "        for _ in range(200):\n",
    "            publisher.publish(pub_msg)\n",
    "            await asyncio.sleep(0.1)\n",
    "        input_images = get_observation(node, Image, '/Camera_rgb', (256, 256, 3))\n",
    "        input_images_wrist = get_observation(node, Image, '/Camera_wrist_rgb', (512, 512, 3))\n",
    "    else:\n",
    "        cur_eff = wait_for_message(node, Float32MultiArray, '/eff_topic').data[0:3]\n",
    "        delta = np.array(pub_msg.data[0:3]) - cur_eff\n",
    "        gripper_eff = pub_msg.data[3]\n",
    "        for i in range(4):\n",
    "            cur_eff += delta/2\n",
    "            pub_msg.data = cur_eff.tolist()\n",
    "            pub_msg.data.append(gripper_eff)\n",
    "            # print(f\"{i}th triggering: \", pub_msg.data)\n",
    "            for _ in range(50):\n",
    "                publisher.publish(pub_msg)\n",
    "                await asyncio.sleep(0.1)\n",
    "        input_images = get_observation(node, Image, '/Camera_rgb', (256, 256, 3))\n",
    "        input_images_wrist = get_observation(node, Image, '/Camera_wrist_rgb', (512, 512, 3))\n",
    "\n",
    "    return input_images, input_images_wrist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted actions:  [0.2688314914703369, 0.06284713000059128, 0.4025217294692993, 0.019915001466870308]\n",
      "New images received\n",
      "Predicted actions:  [0.25711506605148315, 0.06557381898164749, 0.40063047409057617, -0.001128721283748746]\n",
      "New images received\n",
      "Predicted actions:  [0.2579149603843689, 0.06228829175233841, 0.40244895219802856, -0.0034990611020475626]\n",
      "New images received\n",
      "Predicted actions:  [0.256365031003952, 0.0593552328646183, 0.40309444069862366, -0.0033494585659354925]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 43\u001b[0m\n\u001b[1;32m     41\u001b[0m pub_msg\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m pred_eff\n\u001b[1;32m     42\u001b[0m pub_msg\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mappend(pred_gripper)\n\u001b[0;32m---> 43\u001b[0m input_images, input_images_wrist \u001b[38;5;241m=\u001b[39m \u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpublish_efforts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpub_msg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrigger\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m input_images \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m input_images_wrist \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNew images received\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/octo/lib/python3.10/site-packages/nest_asyncio.py:30\u001b[0m, in \u001b[0;36m_patch_asyncio.<locals>.run\u001b[0;34m(main, debug)\u001b[0m\n\u001b[1;32m     28\u001b[0m task \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(main)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m task\u001b[38;5;241m.\u001b[39mdone():\n",
      "File \u001b[0;32m~/anaconda3/envs/octo/lib/python3.10/site-packages/nest_asyncio.py:92\u001b[0m, in \u001b[0;36m_patch_loop.<locals>.run_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m     90\u001b[0m     f\u001b[38;5;241m.\u001b[39m_log_destroy_pending \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f\u001b[38;5;241m.\u001b[39mdone():\n\u001b[0;32m---> 92\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stopping:\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/octo/lib/python3.10/site-packages/nest_asyncio.py:115\u001b[0m, in \u001b[0;36m_patch_loop.<locals>._run_once\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    108\u001b[0m     heappop(scheduled)\n\u001b[1;32m    110\u001b[0m timeout \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ready \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stopping\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mmax\u001b[39m(\n\u001b[1;32m    113\u001b[0m         scheduled[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_when \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime(), \u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m86400\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m scheduled\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 115\u001b[0m event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_events(event_list)\n\u001b[1;32m    118\u001b[0m end_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clock_resolution\n",
      "File \u001b[0;32m~/anaconda3/envs/octo/lib/python3.10/selectors.py:469\u001b[0m, in \u001b[0;36mEpollSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    467\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    468\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 469\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_ev\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    471\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# run inference loop, this model only uses 3rd person image observations for bridge\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "trigger = True\n",
    "while True:\n",
    "\n",
    "    observation = {\n",
    "        'image_primary': np.stack(input_images_stack)[None],\n",
    "        'image_wrist': np.stack(input_images_wrist_stack)[None],\n",
    "        'timestep_pad_mask': np.full((1, np.stack(input_images_stack)[None].shape[1]), True, dtype=bool)\n",
    "    }\n",
    "\n",
    "    # one step actions\n",
    "    actions = model.sample_actions(\n",
    "        observation, \n",
    "        task, \n",
    "        unnormalization_statistics=model.dataset_statistics[\"action\"], \n",
    "        rng=jax.random.PRNGKey(0)\n",
    "    )\n",
    "    actions = actions[0] # remove batch dim\n",
    "    print(\"Predicted actions: \", actions[0,:4].tolist())\n",
    "    pred_actions.append(actions[0,:4].tolist())\n",
    "\n",
    "    # publish actions to robot\n",
    "    pred_eff = actions[0,:3].tolist()\n",
    "    pred_gripper = 1 if actions[0,3] > 0.5 else 0\n",
    "    # pub_msg.data = actions[0,:].tolist()\n",
    "\n",
    "    #### manual triggering\n",
    "    # delta = np.array(pred_eff) - cur_eff\n",
    "    # for i in range(4):\n",
    "    #     cur_eff += delta/2\n",
    "    #     pub_msg.data = cur_eff.tolist()\n",
    "    #     pub_msg.data.append(pred_gripper)\n",
    "    #     # print(f\"{i}th triggering: \", pub_msg.data)\n",
    "    #     for _ in range(20):\n",
    "    #         publisher.publish(pub_msg)\n",
    "    #         sleep(0.1)\n",
    "    # cur_eff = np.array(pred_eff)\n",
    "\n",
    "    pub_msg.data = pred_eff\n",
    "    pub_msg.data.append(pred_gripper)\n",
    "    input_images, input_images_wrist = asyncio.run(publish_efforts(pub_msg, trigger))\n",
    "\n",
    "    if input_images is not None and input_images_wrist is not None:\n",
    "        print(\"New images received\")\n",
    "        # input stack pop front\n",
    "        input_images_stack.pop(0)\n",
    "        input_images_wrist_stack.pop(0)\n",
    "        input_images_stack.append(input_images)\n",
    "        input_images_wrist_stack.append(input_images_wrist)\n",
    "    else:\n",
    "        print(\"No new images received\")\n",
    "        continue\n",
    "\n",
    "\n",
    "    # TODO: how to check if episode is done, then break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### publish random actions\n",
    "pub_msg.data = [0.26, 0.0, 0.4, 0.01] # initial point\n",
    "# pub_msg.data = [0.5, 0.5, 0.2, 0.01]\n",
    "\n",
    "\n",
    "# while rclpy.ok():\n",
    "#     publisher.publish(pub_msg)\n",
    "for i in range(300):\n",
    "    publisher.publish(pub_msg)\n",
    "    sleep(0.1)\n",
    "\n",
    "input_images_stack.pop(0)\n",
    "input_images_wrist_stack.pop(0)\n",
    "input_images = get_observation(node, Image, '/Camera_rgb', (256, 256, 3))\n",
    "input_images_wrist = get_observation(node, Image, '/Camera_wrist_rgb', (512, 512, 3))\n",
    "input_images_stack.append(input_images)\n",
    "input_images_wrist_stack.append(input_images_wrist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "node.destroy_node()\n",
    "rclpy.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(PATH_INFERENCE_RESULTS + \"0923_online_pred_actions.npy\", pred_actions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "octo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
