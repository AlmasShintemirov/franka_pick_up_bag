{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rclpy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from subscriber import Subscriber, sub_call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rclpy.init(args=None)\n",
    "node = Subscriber()\n",
    "\n",
    "camera_image_array = sub_call(node, '/Camera_rgb', (512, 512, 3))\n",
    "if camera_image_array:\n",
    "    node.get_logger().info('Successfully received the latest image!')\n",
    "    plt.imshow(camera_image_array)\n",
    "\n",
    "\n",
    "wrist_image_array = sub_call(node, '/Camera_wrist_rgb', (512, 512, 3))\n",
    "if camera_image_array:\n",
    "    node.get_logger().info('Successfully received the latest image!')\n",
    "    plt.imshow(wrist_image_array)\n",
    "\n",
    "language_msg = sub_call(node, '/language_topic', None)\n",
    "if language_msg:\n",
    "    node.get_logger().info('Successfully received the latest language!')\n",
    "    print(language_msg.data)\n",
    "\n",
    "node.destroy_node()\n",
    "rclpy.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
    "\n",
    "import cv2\n",
    "import jax\n",
    "import tensorflow_datasets as tfds\n",
    "import tqdm\n",
    "import mediapy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_CHECKPOINTS = \"/media/irobotics/Transcend/finetuned_checkpoints/v4_checkpoints/\"\n",
    "PATH_DATASET_ROSBAG = \"/media/irobotics/Transcend/isaacsim_data/v4_test/\"\n",
    "PATH_DATASET_TFDS = '/media/irobotics/Transcend/tensorflow_datasets/v4_test/example_dataset/1.0.0/'\n",
    "PATH_INFERENCE_RESULTS = \"/media/irobotics/Transcend/inference_result/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from octo.model.octo_model import OctoModel\n",
    "\n",
    "model = OctoModel.load_pretrained(PATH_CHECKPOINTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create RLDS dataset builder\n",
    "builder = tfds.builder_from_directory(builder_dir=PATH_DATASET_TFDS)\n",
    "ds = builder.as_dataset(split='train[:2]')\n",
    "iterator = iter(ds)\n",
    "episode = next(iterator)\n",
    "# sample episode + resize to 256x256 (default third-person cam resolution)\n",
    "steps = list(episode['steps'])\n",
    "images = [cv2.resize(np.array(step['observation']['image']), (256, 256)) for step in steps]\n",
    "# extract goal image & language instruction\n",
    "goal_image = images[-1]\n",
    "language_instruction = steps[100]['language_instruction'].numpy().decode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create `task` dict\n",
    "# task = model.create_tasks(goals={\"image_primary\": goal_image[None]})   # for goal-conditioned\n",
    "task = model.create_tasks(goals={\"image_primary\": goal_image})\n",
    "task = model.create_tasks(texts=[language_instruction])                  # for language conditioned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run inference loop, this model only uses 3rd person image observations for bridge\n",
    "# collect predicted and true actions\n",
    "pred_actions= []\n",
    "true_actions = steps[:]['action']\n",
    "while True:\n",
    "    input_images = sub_call(node, '/Camera_rgb', (512, 512, 3))\n",
    "    input_images_wrist = sub_call(node, '/Camera_wrist_rgb', (512, 512, 3))\n",
    "    observation = {\n",
    "        'image_primary': input_images,\n",
    "        'image_wrist': input_images_wrist,\n",
    "        'timestep_pad_mask': np.full((1, input_images.shape[1]), True, dtype=bool)\n",
    "    }\n",
    "    \n",
    "    # this returns *normalized* actions --> we need to unnormalize using the dataset statistics\n",
    "    actions = model.sample_actions(\n",
    "        observation, \n",
    "        task, \n",
    "        unnormalization_statistics=model.dataset_statistics[\"action\"], \n",
    "        rng=jax.random.PRNGKey(0)\n",
    "    )\n",
    "    actions = actions[0] # remove batch dim\n",
    "\n",
    "    pred_actions.append(actions)\n",
    "    # TODO: publish actions to robot\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "octo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
